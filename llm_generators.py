# daily_art/llm_generators.py
from __future__ import annotations

import json
import re
from typing import Dict, Any

from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate

from config import logger


class PostGenerator:
    """
    LLM produces ONLY narrative fields; no URLs/citations generated by the model.
    """
    def __init__(self, model: str = "gpt-4o-mini", temperature: float = 0.67):
        self.llm = ChatOpenAI(model=model, temperature=temperature)
        self.template = ChatPromptTemplate.from_messages(
            [
                (
                    "system",
                    "You are an engaging art narrator for modern readers. "
                    "Write well-researched posts in a vivid, jargon-free style. "
                    "Return ONLY a single JSON object with exactly these keys:\n"
                    "title, year, art_style, artist, artist_info, related_quote, quote_author, "
                    "painting_features, intro, context, meaning, conclusion, museum, unique_fact.\n"
                    "Rules:\n"
                    "- Use the provided SERPER METADATA and WIKIPEDIA SUMMARY as context.\n"
                    "- Do not invent URLs or citations. Do not include fields other than the ones listed.\n"
                    "- Write concise, specific facts; if unknown, use empty strings.",
                ),
                (
                    "human",
                    "SERPER METADATA (JSON):\n{serper_search}\n\n"
                    "WIKIPEDIA SUMMARY (optional):\n{wiki_summary}\n\n"
                    "OUTPUT: Return ONLY the JSON object described above.",
                ),
            ]
        )

    def generate(self, serper_json: Dict[str, Any], wiki_summary: str) -> Dict[str, Any]:
        args = {
            "serper_search": json.dumps(serper_json, ensure_ascii=False),
            "wiki_summary": wiki_summary or "",
        }
        chain = self.template | self.llm
        raw = chain.invoke(args).content

        try:
            data = json.loads(raw)
        except json.JSONDecodeError:
            m = re.search(r"\{[\s\S]*\}", raw)
            if not m:
                logger.error("LLM output is not JSON: %s", raw)
                raise
            data = json.loads(m.group())
        return data


class RefinementGenerator:
    """
    Takes an existing ArtPost JSON + user comments and improves only narrative fields.
    Must preserve structure and URLs/citations.
    """
    def __init__(self, model: str = "gpt-4o-mini", temperature: float = 0.4):
        self.llm = ChatOpenAI(model=model, temperature=temperature)
        self.template = ChatPromptTemplate.from_messages(
            [
                (
                    "system",
                    "You refine an existing art post JSON. "
                    "You ONLY edit narrative string fields to follow the comments. "
                    "Do NOT add or remove keys. "
                    "Do NOT change painting_urls or citations. "
                    "Return ONLY valid JSON with the same keys as input.",
                ),
                (
                    "human",
                    "ORIGINAL JSON:\n{original_json}\n\n"
                    "USER COMMENTS / INSTRUCTIONS:\n{comments}\n\n"
                    "OUTPUT: refined JSON object.",
                ),
            ]
        )

    def refine(self, original: dict, comments: str) -> dict:
        args = {
            "original_json": json.dumps(original, ensure_ascii=False, indent=2),
            "comments": comments,
        }
        chain = self.template | self.llm
        raw = chain.invoke(args).content
        try:
            data = json.loads(raw)
        except json.JSONDecodeError:
            m = re.search(r"\{[\s\S]*\}", raw)
            if not m:
                raise
            data = json.loads(m.group())
        return data
